{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Assignment1_MultiLabelClassification_Template.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verarararaya/Multi-label-Classsification/blob/master/Assignment1_MultiLabelClassification_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krCbrrtxPnKF",
        "colab_type": "text"
      },
      "source": [
        "# COMP47590: Advanced Machine Learning\n",
        "# Assignment 1: Multi-label Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9-dMOTRPnKJ",
        "colab_type": "text"
      },
      "source": [
        "Name(s): \n",
        "\n",
        "Student Number(s):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP3Wf9ecPnLh",
        "colab_type": "text"
      },
      "source": [
        "## Import Packages Etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrQz3CfUPnLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "# import other useful packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjkdiI-8PnLq",
        "colab_type": "text"
      },
      "source": [
        "## Task 0: Load the Yeast Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzVyilDAPnLr",
        "colab_type": "code",
        "outputId": "006a4ae4-c150-48e2-d166-e02cd424490a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "# Write your code here\n",
        "data_sampling_rate = 0.1\n",
        "cv_folds = 10\n",
        "dataset = pd.read_csv('yeast.csv')\n",
        "# dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
        "num_classes = 14\n",
        "display(dataset.head())\n",
        "print(dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Att1</th>\n",
              "      <th>Att2</th>\n",
              "      <th>Att3</th>\n",
              "      <th>Att4</th>\n",
              "      <th>Att5</th>\n",
              "      <th>Att6</th>\n",
              "      <th>Att7</th>\n",
              "      <th>Att8</th>\n",
              "      <th>Att9</th>\n",
              "      <th>Att10</th>\n",
              "      <th>Att11</th>\n",
              "      <th>Att12</th>\n",
              "      <th>Att13</th>\n",
              "      <th>Att14</th>\n",
              "      <th>Att15</th>\n",
              "      <th>Att16</th>\n",
              "      <th>Att17</th>\n",
              "      <th>Att18</th>\n",
              "      <th>Att19</th>\n",
              "      <th>Att20</th>\n",
              "      <th>Att21</th>\n",
              "      <th>Att22</th>\n",
              "      <th>Att23</th>\n",
              "      <th>Att24</th>\n",
              "      <th>Att25</th>\n",
              "      <th>Att26</th>\n",
              "      <th>Att27</th>\n",
              "      <th>Att28</th>\n",
              "      <th>Att29</th>\n",
              "      <th>Att30</th>\n",
              "      <th>Att31</th>\n",
              "      <th>Att32</th>\n",
              "      <th>Att33</th>\n",
              "      <th>Att34</th>\n",
              "      <th>Att35</th>\n",
              "      <th>Att36</th>\n",
              "      <th>Att37</th>\n",
              "      <th>Att38</th>\n",
              "      <th>Att39</th>\n",
              "      <th>Att40</th>\n",
              "      <th>...</th>\n",
              "      <th>Att78</th>\n",
              "      <th>Att79</th>\n",
              "      <th>Att80</th>\n",
              "      <th>Att81</th>\n",
              "      <th>Att82</th>\n",
              "      <th>Att83</th>\n",
              "      <th>Att84</th>\n",
              "      <th>Att85</th>\n",
              "      <th>Att86</th>\n",
              "      <th>Att87</th>\n",
              "      <th>Att88</th>\n",
              "      <th>Att89</th>\n",
              "      <th>Att90</th>\n",
              "      <th>Att91</th>\n",
              "      <th>Att92</th>\n",
              "      <th>Att93</th>\n",
              "      <th>Att94</th>\n",
              "      <th>Att95</th>\n",
              "      <th>Att96</th>\n",
              "      <th>Att97</th>\n",
              "      <th>Att98</th>\n",
              "      <th>Att99</th>\n",
              "      <th>Att100</th>\n",
              "      <th>Att101</th>\n",
              "      <th>Att102</th>\n",
              "      <th>Att103</th>\n",
              "      <th>Class1</th>\n",
              "      <th>Class2</th>\n",
              "      <th>Class3</th>\n",
              "      <th>Class4</th>\n",
              "      <th>Class5</th>\n",
              "      <th>Class6</th>\n",
              "      <th>Class7</th>\n",
              "      <th>Class8</th>\n",
              "      <th>Class9</th>\n",
              "      <th>Class10</th>\n",
              "      <th>Class11</th>\n",
              "      <th>Class12</th>\n",
              "      <th>Class13</th>\n",
              "      <th>Class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.004168</td>\n",
              "      <td>-0.170975</td>\n",
              "      <td>-0.156748</td>\n",
              "      <td>-0.142151</td>\n",
              "      <td>0.058781</td>\n",
              "      <td>0.026851</td>\n",
              "      <td>0.197719</td>\n",
              "      <td>0.041850</td>\n",
              "      <td>0.066938</td>\n",
              "      <td>-0.056617</td>\n",
              "      <td>-0.027230</td>\n",
              "      <td>-0.137411</td>\n",
              "      <td>0.067776</td>\n",
              "      <td>0.047175</td>\n",
              "      <td>0.155671</td>\n",
              "      <td>0.050766</td>\n",
              "      <td>0.102557</td>\n",
              "      <td>-0.020259</td>\n",
              "      <td>-0.200512</td>\n",
              "      <td>-0.095371</td>\n",
              "      <td>-0.081940</td>\n",
              "      <td>-0.103735</td>\n",
              "      <td>0.093299</td>\n",
              "      <td>0.105475</td>\n",
              "      <td>0.148560</td>\n",
              "      <td>0.085925</td>\n",
              "      <td>0.107879</td>\n",
              "      <td>0.108075</td>\n",
              "      <td>0.085388</td>\n",
              "      <td>0.124026</td>\n",
              "      <td>-0.003650</td>\n",
              "      <td>-0.127376</td>\n",
              "      <td>0.039394</td>\n",
              "      <td>-0.018364</td>\n",
              "      <td>0.050378</td>\n",
              "      <td>0.157190</td>\n",
              "      <td>0.203563</td>\n",
              "      <td>0.111552</td>\n",
              "      <td>0.017907</td>\n",
              "      <td>-0.001126</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175325</td>\n",
              "      <td>-0.133636</td>\n",
              "      <td>0.005524</td>\n",
              "      <td>-0.014981</td>\n",
              "      <td>-0.031946</td>\n",
              "      <td>-0.015114</td>\n",
              "      <td>-0.047175</td>\n",
              "      <td>0.003829</td>\n",
              "      <td>0.010967</td>\n",
              "      <td>-0.006062</td>\n",
              "      <td>-0.027560</td>\n",
              "      <td>-0.019866</td>\n",
              "      <td>-0.024046</td>\n",
              "      <td>-0.025153</td>\n",
              "      <td>-0.009261</td>\n",
              "      <td>-0.025539</td>\n",
              "      <td>0.006166</td>\n",
              "      <td>-0.012976</td>\n",
              "      <td>-0.014259</td>\n",
              "      <td>-0.015024</td>\n",
              "      <td>-0.010747</td>\n",
              "      <td>0.000411</td>\n",
              "      <td>-0.032056</td>\n",
              "      <td>-0.018312</td>\n",
              "      <td>0.030126</td>\n",
              "      <td>0.124722</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103956</td>\n",
              "      <td>0.011879</td>\n",
              "      <td>-0.098986</td>\n",
              "      <td>-0.054501</td>\n",
              "      <td>-0.007970</td>\n",
              "      <td>0.049113</td>\n",
              "      <td>-0.030580</td>\n",
              "      <td>-0.077933</td>\n",
              "      <td>-0.080529</td>\n",
              "      <td>-0.016267</td>\n",
              "      <td>-0.215304</td>\n",
              "      <td>-0.009885</td>\n",
              "      <td>-0.155843</td>\n",
              "      <td>-0.059522</td>\n",
              "      <td>-0.098836</td>\n",
              "      <td>-0.071141</td>\n",
              "      <td>-0.023494</td>\n",
              "      <td>-0.071200</td>\n",
              "      <td>0.027767</td>\n",
              "      <td>0.003091</td>\n",
              "      <td>-0.003761</td>\n",
              "      <td>0.074600</td>\n",
              "      <td>0.053080</td>\n",
              "      <td>-0.008138</td>\n",
              "      <td>0.001794</td>\n",
              "      <td>-0.111704</td>\n",
              "      <td>-0.140291</td>\n",
              "      <td>-0.063347</td>\n",
              "      <td>0.066767</td>\n",
              "      <td>-0.167073</td>\n",
              "      <td>-0.095567</td>\n",
              "      <td>-0.047209</td>\n",
              "      <td>0.082206</td>\n",
              "      <td>0.144445</td>\n",
              "      <td>0.086581</td>\n",
              "      <td>-0.111850</td>\n",
              "      <td>-0.086560</td>\n",
              "      <td>0.024942</td>\n",
              "      <td>-0.131539</td>\n",
              "      <td>0.080062</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001249</td>\n",
              "      <td>-0.020209</td>\n",
              "      <td>-0.077359</td>\n",
              "      <td>-0.045139</td>\n",
              "      <td>-0.074738</td>\n",
              "      <td>0.051846</td>\n",
              "      <td>0.009323</td>\n",
              "      <td>0.184332</td>\n",
              "      <td>0.420424</td>\n",
              "      <td>-0.090224</td>\n",
              "      <td>-0.090718</td>\n",
              "      <td>-0.035266</td>\n",
              "      <td>-0.046729</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>-0.066023</td>\n",
              "      <td>-0.051916</td>\n",
              "      <td>0.007680</td>\n",
              "      <td>0.027719</td>\n",
              "      <td>-0.085811</td>\n",
              "      <td>0.111123</td>\n",
              "      <td>0.050541</td>\n",
              "      <td>0.027565</td>\n",
              "      <td>-0.063569</td>\n",
              "      <td>-0.041471</td>\n",
              "      <td>-0.079758</td>\n",
              "      <td>0.017161</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.509949</td>\n",
              "      <td>0.401709</td>\n",
              "      <td>0.293799</td>\n",
              "      <td>0.087714</td>\n",
              "      <td>0.011686</td>\n",
              "      <td>-0.006411</td>\n",
              "      <td>-0.006255</td>\n",
              "      <td>0.013646</td>\n",
              "      <td>-0.040666</td>\n",
              "      <td>-0.024447</td>\n",
              "      <td>-0.040576</td>\n",
              "      <td>0.014326</td>\n",
              "      <td>-0.074968</td>\n",
              "      <td>0.141365</td>\n",
              "      <td>-0.015182</td>\n",
              "      <td>0.013691</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>0.003736</td>\n",
              "      <td>-0.020726</td>\n",
              "      <td>-0.044104</td>\n",
              "      <td>-0.052959</td>\n",
              "      <td>-0.085572</td>\n",
              "      <td>-0.061547</td>\n",
              "      <td>-0.029578</td>\n",
              "      <td>0.027700</td>\n",
              "      <td>-0.094310</td>\n",
              "      <td>-0.047721</td>\n",
              "      <td>-0.081589</td>\n",
              "      <td>-0.022846</td>\n",
              "      <td>-0.106684</td>\n",
              "      <td>-0.068873</td>\n",
              "      <td>-0.105225</td>\n",
              "      <td>-0.065414</td>\n",
              "      <td>-0.047722</td>\n",
              "      <td>-0.070723</td>\n",
              "      <td>-0.057425</td>\n",
              "      <td>-0.042024</td>\n",
              "      <td>-0.034122</td>\n",
              "      <td>-0.049606</td>\n",
              "      <td>0.015137</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002432</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>-0.083572</td>\n",
              "      <td>-0.096943</td>\n",
              "      <td>0.148457</td>\n",
              "      <td>-0.007413</td>\n",
              "      <td>0.130691</td>\n",
              "      <td>-0.032325</td>\n",
              "      <td>0.028612</td>\n",
              "      <td>-0.023051</td>\n",
              "      <td>-0.092214</td>\n",
              "      <td>-0.103336</td>\n",
              "      <td>0.138232</td>\n",
              "      <td>-0.100351</td>\n",
              "      <td>0.140423</td>\n",
              "      <td>0.110074</td>\n",
              "      <td>0.096277</td>\n",
              "      <td>-0.044932</td>\n",
              "      <td>-0.089470</td>\n",
              "      <td>-0.009162</td>\n",
              "      <td>-0.012010</td>\n",
              "      <td>0.308378</td>\n",
              "      <td>-0.028053</td>\n",
              "      <td>0.026710</td>\n",
              "      <td>-0.066565</td>\n",
              "      <td>-0.122352</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.119092</td>\n",
              "      <td>0.004412</td>\n",
              "      <td>-0.002262</td>\n",
              "      <td>0.072254</td>\n",
              "      <td>0.044512</td>\n",
              "      <td>-0.051467</td>\n",
              "      <td>0.074686</td>\n",
              "      <td>-0.007670</td>\n",
              "      <td>0.079438</td>\n",
              "      <td>0.062184</td>\n",
              "      <td>-0.013027</td>\n",
              "      <td>0.045538</td>\n",
              "      <td>0.080412</td>\n",
              "      <td>-0.010042</td>\n",
              "      <td>0.013029</td>\n",
              "      <td>-0.071975</td>\n",
              "      <td>0.089818</td>\n",
              "      <td>-0.016129</td>\n",
              "      <td>0.033105</td>\n",
              "      <td>0.024275</td>\n",
              "      <td>0.040428</td>\n",
              "      <td>0.064248</td>\n",
              "      <td>0.225613</td>\n",
              "      <td>0.176576</td>\n",
              "      <td>0.015501</td>\n",
              "      <td>0.009491</td>\n",
              "      <td>-0.013684</td>\n",
              "      <td>-0.017633</td>\n",
              "      <td>0.085007</td>\n",
              "      <td>-0.056274</td>\n",
              "      <td>-0.088925</td>\n",
              "      <td>-0.062951</td>\n",
              "      <td>0.227151</td>\n",
              "      <td>0.165897</td>\n",
              "      <td>0.150224</td>\n",
              "      <td>0.065105</td>\n",
              "      <td>0.110891</td>\n",
              "      <td>0.048451</td>\n",
              "      <td>0.114726</td>\n",
              "      <td>0.020393</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.111806</td>\n",
              "      <td>-0.154732</td>\n",
              "      <td>0.302807</td>\n",
              "      <td>0.340027</td>\n",
              "      <td>-0.093332</td>\n",
              "      <td>-0.057848</td>\n",
              "      <td>-0.010558</td>\n",
              "      <td>-0.039194</td>\n",
              "      <td>-0.041628</td>\n",
              "      <td>-0.077455</td>\n",
              "      <td>-0.008553</td>\n",
              "      <td>-0.022404</td>\n",
              "      <td>-0.106131</td>\n",
              "      <td>-0.103067</td>\n",
              "      <td>-0.083059</td>\n",
              "      <td>-0.089064</td>\n",
              "      <td>-0.083809</td>\n",
              "      <td>0.200354</td>\n",
              "      <td>-0.075716</td>\n",
              "      <td>0.196605</td>\n",
              "      <td>0.152758</td>\n",
              "      <td>-0.028484</td>\n",
              "      <td>-0.074207</td>\n",
              "      <td>-0.089227</td>\n",
              "      <td>-0.049913</td>\n",
              "      <td>-0.043893</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.042037</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>-0.069483</td>\n",
              "      <td>0.081015</td>\n",
              "      <td>-0.048207</td>\n",
              "      <td>0.089446</td>\n",
              "      <td>-0.004947</td>\n",
              "      <td>0.064456</td>\n",
              "      <td>-0.133387</td>\n",
              "      <td>0.068878</td>\n",
              "      <td>-0.139371</td>\n",
              "      <td>0.041487</td>\n",
              "      <td>-0.058531</td>\n",
              "      <td>0.021264</td>\n",
              "      <td>-0.101382</td>\n",
              "      <td>0.021015</td>\n",
              "      <td>0.096572</td>\n",
              "      <td>-0.005136</td>\n",
              "      <td>0.111104</td>\n",
              "      <td>-0.008323</td>\n",
              "      <td>0.020210</td>\n",
              "      <td>-0.003967</td>\n",
              "      <td>0.039762</td>\n",
              "      <td>0.006744</td>\n",
              "      <td>-0.041730</td>\n",
              "      <td>-0.174533</td>\n",
              "      <td>-0.101343</td>\n",
              "      <td>-0.115674</td>\n",
              "      <td>0.328511</td>\n",
              "      <td>-0.108945</td>\n",
              "      <td>-0.160748</td>\n",
              "      <td>-0.120290</td>\n",
              "      <td>-0.148308</td>\n",
              "      <td>-0.082882</td>\n",
              "      <td>-0.127218</td>\n",
              "      <td>-0.167186</td>\n",
              "      <td>-0.143210</td>\n",
              "      <td>-0.118028</td>\n",
              "      <td>-0.297516</td>\n",
              "      <td>-0.160082</td>\n",
              "      <td>...</td>\n",
              "      <td>0.108388</td>\n",
              "      <td>0.095516</td>\n",
              "      <td>0.015942</td>\n",
              "      <td>0.087354</td>\n",
              "      <td>0.176911</td>\n",
              "      <td>-0.062311</td>\n",
              "      <td>0.117205</td>\n",
              "      <td>-0.048277</td>\n",
              "      <td>-0.053679</td>\n",
              "      <td>0.014850</td>\n",
              "      <td>-0.066453</td>\n",
              "      <td>-0.067962</td>\n",
              "      <td>-0.083653</td>\n",
              "      <td>-0.081130</td>\n",
              "      <td>-0.061469</td>\n",
              "      <td>0.023662</td>\n",
              "      <td>-0.060467</td>\n",
              "      <td>0.044351</td>\n",
              "      <td>-0.057209</td>\n",
              "      <td>0.028047</td>\n",
              "      <td>0.029661</td>\n",
              "      <td>-0.050026</td>\n",
              "      <td>0.023248</td>\n",
              "      <td>-0.061539</td>\n",
              "      <td>-0.035160</td>\n",
              "      <td>0.067834</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 117 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Att1      Att2      Att3      Att4  ...  Class11  Class12  Class13  Class14\n",
              "0  0.004168 -0.170975 -0.156748 -0.142151  ...        0        1        1        0\n",
              "1 -0.103956  0.011879 -0.098986 -0.054501  ...        0        0        0        0\n",
              "2  0.509949  0.401709  0.293799  0.087714  ...        0        1        1        0\n",
              "3  0.119092  0.004412 -0.002262  0.072254  ...        0        0        0        0\n",
              "4  0.042037  0.007054 -0.069483  0.081015  ...        0        0        0        0\n",
              "\n",
              "[5 rows x 117 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(2417, 117)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5-ouF5iPnLv",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Implement the Binary Relevance Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ne8r36uPnLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n",
        "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, add_noise = False):\n",
        "        self.add_noise = add_noise\n",
        "        \n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, data, functions):    \n",
        "        # Create a new empty dictionary into which we will store relevance\n",
        "        self.relevances_ = dict()\n",
        "\n",
        "        # Iterate all functioins\n",
        "        for i in range(14):\n",
        "            status = functions[:,i]\n",
        "            status_squeeze = np.squeeze(status)\n",
        "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(data, status_squeeze)\n",
        "            \n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['relevances_'])\n",
        "\n",
        "        # Initialise an empty list to store the predictions made\n",
        "        pos_functions = list()\n",
        "        \n",
        "        # Iterate all functioins to predict\n",
        "        for i in range(14):\n",
        "            pos_functions.append(self.relevances_[i].predict(X))\n",
        "            \n",
        "        return np.array(pos_functions).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzbJT9-uhHm-",
        "colab_type": "code",
        "outputId": "cf33cd0d-6e88-4dae-fbc4-05993e7236a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "my_model = BinaryRelevanceClassifier()\n",
        "my_model.fit(np.array(dataset.iloc[:40,:103]), np.array(dataset.iloc[:40,103:]))\n",
        "my_model.predict(np.array(dataset.iloc[41:49,:103]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9t-99gDPnL1",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Implement the Binary Relevance Algorithm with Under-Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWt73KgPnL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n",
        "class BinaryRelevanceClassifier(BaseEstimator, ClassifierMixin):\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, add_noise = False,under_sampling='undersampling'):\n",
        "        self.add_noise = add_noise\n",
        "        self.under_sampling = under_sampling\n",
        "        \n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, data, functions): \n",
        "        # Create a new empty dictionary into which we will store relevance \n",
        "        self.relevances_ = dict()  \n",
        "        if self.under_sampling == 'undersampling':\n",
        "          for i in range(14):\n",
        "            status = functions[:,i]\n",
        "            status_squeeze = np.squeeze(status)\n",
        "            rus = RandomUnderSampler(random_state=0)\n",
        "            X_resampled, y_resampled = rus.fit_sample(data, status)\n",
        "            # print(X_resampled.shape)\n",
        "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(X_resampled, y_resampled)\n",
        "        elif self.under_sampling == 'noundersampling':\n",
        "          for i in range(14):\n",
        "            status = functions[:,i]\n",
        "            status_squeeze = np.squeeze(status)\n",
        "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(data, status_squeeze)\n",
        "        \n",
        "\n",
        "\n",
        "        # Iterate all functioins\n",
        "        \n",
        "            \n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['relevances_'])\n",
        "\n",
        "        # Initialise an empty list to store the predictions made\n",
        "        pos_functions = list()\n",
        "        \n",
        "        # Iterate all functioins to predict\n",
        "        for i in range(14):\n",
        "            pos_functions.append(self.relevances_[i].predict(X))\n",
        "            \n",
        "        return np.array(pos_functions).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TN_AKvfkeoR",
        "colab_type": "code",
        "outputId": "7ab02ee9-aa0f-41dc-fc2a-9fb191f64eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "my_model = BinaryRelevanceClassifier(under_sampling='undersampling')\n",
        "my_model.fit(np.array(dataset.iloc[:1000,:103]), np.array(dataset.iloc[:1000,103:]))\n",
        "my_model.predict(np.array(dataset.iloc[1001:1009,:103]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpqXLrZnPnL7",
        "colab_type": "text"
      },
      "source": [
        "## Task 3: Compare the Performance of Different Binary Relevance Approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJQaTWIxPnL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osr3Vh5JPnMA",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Implement the Classifier Chains Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0YwaWVJPnMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n",
        "class ClassChainsClassifier(BaseEstimator, ClassifierMixin):\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, add_noise = False):\n",
        "        self.add_noise = add_noise\n",
        "        \n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, data, functions):    \n",
        "        # Create a new empty dictionary into which we will store relevance\n",
        "        self.relevances_ = dict()\n",
        "\n",
        "        # Iterate all functioins\n",
        "        for i in range(14):\n",
        "            status = functions[:,i]\n",
        "            status_squeeze = np.squeeze(status)\n",
        "            # print(status_squeeze.shape)\n",
        "            # print(type(functions))\n",
        "            # print(type(data))\n",
        "            self.relevances_[i] = BaggingClassifier(n_estimators=10, random_state=0).fit(data,status_squeeze)\n",
        "            data = np.concatenate((data,np.reshape(status_squeeze,(data.shape[0],1))),axis=1)\n",
        "            \n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['relevances_'])\n",
        "\n",
        "        # Initialise an empty list to store the predictions made\n",
        "        pos_functions = list()\n",
        "        j = 0\n",
        "        # Iterate all functioins to predict\n",
        "        for i in range(14):\n",
        "            j = 103+i\n",
        "            # if len(X) > 0:\n",
        "            pos_functions.append(self.relevances_[i].predict(X[:,:j]))\n",
        "            \n",
        "        return np.array(pos_functions).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a825f9da-c409-400a-9739-e6b082d3d6f7",
        "id": "OtAyFWYHHFPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "my_model = ClassChainsClassifier()\n",
        "my_model.fit(np.array(dataset.iloc[:1000,:103]), np.array(dataset.iloc[:1000,103:]))\n",
        "my_model.predict(np.array(dataset.iloc[1001:1119,:]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 1, 0],\n",
              "       [1, 1, 0, ..., 1, 1, 0],\n",
              "       [1, 0, 0, ..., 1, 1, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 1, 0],\n",
              "       [0, 1, 1, ..., 1, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4TBzeIxPnMF",
        "colab_type": "text"
      },
      "source": [
        "## Task 5: Evaluate the Performance of the Classifier Chains Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5BfHfFqPnMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write your code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2OOZlaXPnMK",
        "colab_type": "text"
      },
      "source": [
        "## Task 6: Reflect on the Performance of the Different Models Evaluated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndNXlCepP2uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPFsbjnWPnML",
        "colab_type": "text"
      },
      "source": [
        "*Write your reflection here (max 300 words)*\n"
      ]
    }
  ]
}